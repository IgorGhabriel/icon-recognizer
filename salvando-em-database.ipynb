{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "# import csv\n",
    "\n",
    "from wand.image import Image as wImg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import ast\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# from scipy.spatial.distance import euclidean\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Torch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo desse programa é:\n",
    "\n",
    "\n",
    "função: ler_svg\n",
    "\n",
    "ler arquivos .svg, salvar o nome e o path para cada arquivo em um data frame\n",
    "\n",
    "nome do dataframe vai ser: icons-data-base\n",
    "coluna dos nome dos arquivos .svg: Nome\n",
    "coluna com os paths dos arquivos .svg: svg path\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "função: converter_svg_para_png\n",
    "\n",
    "transformar os arquivos .svg em .png\n",
    "\n",
    "através da coluna: svg path, abrirei os arquivos e converterei em .png e salvarei em uma nova pasta, chamada icons-png-database\n",
    "o nome de cada arquivo .png será escrito de acordo com a coluna: Nome\n",
    "\n",
    "salvarei o path para os arquivos .png em uma coluna do data frame chamada: png path\n",
    "\n",
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "função: converter_png_em_pil_image\n",
    "\n",
    "converterei os arquivos .png em PIL Image\n",
    "\n",
    "a função vai ler o path para os arquivos .png através da coluna: png path\n",
    "\n",
    "salvarei os arquivos PIL Image em uma lista chamada: icons_pil_images\n",
    "\n",
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "função: converter_pil_em_tensor\n",
    "\n",
    "converterei as PIL Image em torch.tensor\n",
    "\n",
    "a função para converter irá converter as images da lista icons_pil_images\n",
    "\n",
    "o tensor de cada imagem será salvo em uma nova coluna do data frame: Tensor\n",
    "\n",
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "função: analisar_tensor\n",
    "\n",
    "Irei analisar cada tensor para extrair as caracteristicas de cada imagem\n",
    "\n",
    "os tensores serão dados atraves da coluna do data frame: Tensor\n",
    "\n",
    "a função ira retornar as caracteristicas de cada imagem em forma de arrays, \n",
    "esses arrays serão salvos em uma nova coluna do data frame chamada: Caracteristicas Array\n",
    "\n",
    "------------------------------------------------------------------------------------\n",
    "\n",
    "tenho que ser capas de salvar os arrays e tensores em um arquivo para depois usa-los em um outro programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_svg(path_to_svgs):\n",
    "\n",
    "    path_svgs = glob.glob(os.path.join(path_to_svgs, '*.svg'))\n",
    "\n",
    "    nome_svgs = list()\n",
    "\n",
    "    # colocando o nome dos arquivos .svg na lista: nome_svgs\n",
    "    for path in path_svgs:\n",
    "\n",
    "        nome_n_formatado = path.rsplit((\"\\\\\"))[-1]\n",
    "        nome_formatado = nome_n_formatado.replace(\".svg\" , \"\")\n",
    "        nome_svgs.append(nome_formatado)\n",
    "\n",
    "    icons_data_base = pd.DataFrame({ 'Nome': nome_svgs, 'svg path': path_svgs})\n",
    "\n",
    "    return icons_data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_data_base = ler_svg(r'material-design-icons\\svg\\filled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_svg_para_png(data_base, pasta_dos_pngs='icons-png-database'):\n",
    "    \n",
    "    if not os.path.exists(pasta_dos_pngs):\n",
    "        os.makedirs(pasta_dos_pngs)\n",
    "\n",
    "    png_paths = list()\n",
    "\n",
    "    for i, row in data_base.iterrows():\n",
    "        svg_path = row['svg path']\n",
    "        nome = row['Nome']\n",
    "\n",
    "        nome_arq_png = f\"{nome}.png\"\n",
    "        png_path = os.path.join(pasta_dos_pngs, nome_arq_png)\n",
    "\n",
    "        with wImg(filename = svg_path) as img:\n",
    "            img.format = 'png'\n",
    "            img.save(filename = png_path)\n",
    "            png_paths.append(png_path)\n",
    "\n",
    "    data_base['png path'] = png_paths\n",
    "\n",
    "    return data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_data_base = converter_svg_para_png(icons_data_base, 'icons-png-database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_png_em_pil_image(data_base, pasta_dos_pngs='icons-png-database'):\n",
    "    \n",
    "    icons_pil_image = list()\n",
    "    \n",
    "    for filename in os.listdir(pasta_dos_pngs):\n",
    "        path = os.path.join(pasta_dos_pngs, filename)\n",
    "        icon = Image.open(path).convert('RGB')\n",
    "\n",
    "        icons_pil_image.append(icon)\n",
    "\n",
    "\n",
    "    data_base['PIL Image'] = icons_pil_image\n",
    "    \n",
    "    return data_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_data_base = converter_png_em_pil_image(icons_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter_pil_em_tensor(data_base):\n",
    "    \n",
    "    lista_tensores = list()\n",
    "\n",
    "    img = v2.Compose([\n",
    "                    v2.Resize((224, 224)),\n",
    "                    v2.ToImage(), \n",
    "                    v2.ToDtype(torch.float32, scale=True),\n",
    "                    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    for pil_image in data_base['PIL Image']:\n",
    "\n",
    "        img_tensor = img(pil_image)\n",
    "   \n",
    "        lista_tensores.append(pickle.dumps(img_tensor).decode('latin1'))\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    data_base['Tensor'] = lista_tensores\n",
    "\n",
    "\n",
    "    return data_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_data_base = converter_pil_em_tensor(icons_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analisar_tensor(data_base, batch_size = 20):\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     model = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
    "#     model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "#     model.to(device).eval()\n",
    "\n",
    "#     dataloader = DataLoader(data_base['Tensor'], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     array_caracteristicas = list()\n",
    "\n",
    "#     for batch in dataloader:\n",
    "            \n",
    "#             imagem = batch.to(device)  # Ensure the batch is on the GPU\n",
    "#             if imagem.dim() == 3:  # Check if input is 3D and add batch dimension\n",
    "#                 imagem = imagem.unsqueeze(0)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 try:\n",
    "                    \n",
    "#                     features = model(imagem).squeeze()  # Remove batch and singleton dimensions if necessary\n",
    "#                     array_caracteristicas.extend(features.cpu().numpy())  # Move back to CPU for numpy conversion\n",
    "\n",
    "#                 except RuntimeError as e:\n",
    "\n",
    "#                     print(f\"RuntimeError: {e}\")\n",
    "#                     # Reduce batch size if running out of memory\n",
    "#                     batch_size = max(1, batch_size // 2)\n",
    "#                     dataloader = DataLoader(data_base['Tensor'], batch_size=batch_size, shuffle=False)\n",
    "#                     array_caracteristicas = list()\n",
    "\n",
    "#                     break\n",
    "\n",
    "#     return np.array(array_caracteristicas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_tensores(data_base, batch_size=20):\n",
    "\n",
    "    def desserializar_tensores(data_base):\n",
    "        \n",
    "        tensores_originais = list()\n",
    "\n",
    "        for tensor_serializado in data_base['Tensor']:\n",
    "            tensor_original = pickle.loads(tensor_serializado.encode('latin1'))\n",
    "            tensores_originais.append(tensor_original)\n",
    "\n",
    "        return tensores_originais    \n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    tensores = desserializar_tensores(data_base)\n",
    "\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "    model.to(device).eval()\n",
    "\n",
    "\n",
    "    dataloader = DataLoader(tensores, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    array_caracteristicas = list()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            for batch in dataloader:\n",
    "\n",
    "                batch_tensors = [item.clone().detach() for item in batch]\n",
    "                batch_tensors = torch.stack(batch_tensors).to(device)\n",
    "                \n",
    "                if batch_tensors.dim() == 3:\n",
    "                    batch_tensors = batch_tensors.unsqueeze(0)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    features = model(batch_tensors).squeeze()  \n",
    "                    array_caracteristicas.extend(features.cpu().numpy())\n",
    "\n",
    "            break\n",
    "\n",
    "        except RuntimeError as e:\n",
    "\n",
    "            print(f\"RuntimeError: {e}\")\n",
    "           \n",
    "            if \"out of memory\" in str(e):\n",
    "\n",
    "                batch_size = max(1, batch_size // 2)\n",
    "\n",
    "                print(f\"Reducing batch size to {batch_size} and retrying...\")\n",
    "\n",
    "                dataloader = DataLoader(tensores, batch_size=batch_size, shuffle=False)\n",
    "                array_caracteristicas = list()\n",
    "\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    voltando_bytes = list()      \n",
    "    for tensor in data_base['Tensor']:\n",
    "   \n",
    "        voltando_bytes.append(pickle.dumps(tensor).decode('latin1'))\n",
    "    \n",
    "    data_base['Tensor'] = voltando_bytes\n",
    "            \n",
    "    data_base['Array características'] = array_caracteristicas[:len(data_base)]\n",
    "\n",
    "    data_base['Array características'] = data_base['Array características'].apply(lambda x: np.array2string(x, separator=','))\n",
    "\n",
    "    return data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_data_base = analisar_tensores(icons_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_dataframe(data_base, nome_arquivo_csv):\n",
    "    data_base.to_csv(nome_arquivo_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salvar_dataframe(icons_data_base, 'new-icon-db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_dataframe(nome_arquivo_csv = \"icons-data-base.csv\"):\n",
    "\n",
    "    nome_data_base = pd.read_csv(nome_arquivo_csv)\n",
    "    nome_data_base['Array características'] = nome_data_base['Array características'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "    nome_data_base['Tensor'] = nome_data_base['Tensor'].apply(lambda x: x.encode('latin1'))\n",
    "\n",
    "    return nome_data_base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_icon_db = ler_dataframe('new-icon-db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_to_svgs, pasta_dos_pngs = 'icons-png-database', batch_size = 20, nome_arquivo_csv = 'icons-data-frame.csv'):\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Torch device: {device}\")\n",
    "\n",
    "    data_base = ler_svg(path_to_svgs)\n",
    "\n",
    "    data_base = converter_svg_para_png(data_base, pasta_dos_pngs)\n",
    "\n",
    "    data_base = converter_png_em_pil_image(data_base, pasta_dos_pngs)\n",
    "\n",
    "    data_base = converter_pil_em_tensor(data_base)\n",
    "\n",
    "    data_base = analisar_tensores(data_base, analisar_tensores(data_base, batch_size))\n",
    "\n",
    "    salvar_dataframe(data_base, nome_arquivo_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(r'material-design-icons\\svg\\filled')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
