{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IgorG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Pytorch's device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the database with the icons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons_db = pd.read_csv(\"icons.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load the icons database and adds to it the image that we want to find some icons that resembles it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_icons_from_db(db_path, target_icon_path):\n",
    "\n",
    "    icons = []\n",
    "    caminhos = []\n",
    "\n",
    "    for filename in os.listdir(db_path):\n",
    "        path = os.path.join(db_path, filename)\n",
    "        icon = Image.open(path).convert('RGB')\n",
    "        icons.append(icon)\n",
    "        caminhos.append(path)\n",
    "\n",
    "    target_icon = Image.open(target_icon_path).convert('RGB')\n",
    "    \n",
    "    icons.append(target_icon)\n",
    "    caminhos.append(target_icon_path)\n",
    "    \n",
    "\n",
    "    return icons, caminhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pre process the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icon_pre_process(icons, height = 224, width = 224):\n",
    "    pre_processed_icons = []\n",
    "\n",
    "    \n",
    "    img = v2.Compose([\n",
    "                    v2.Resize((height, width)),\n",
    "                    v2.ToImage(), \n",
    "                    v2.ToDtype(torch.float32, scale=True),\n",
    "                    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "        \n",
    "    for i in icons:\n",
    "        icon = img(i)\n",
    "        pre_processed_icons.append(icon)\n",
    "\n",
    "    return pre_processed_icons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract the characteristics from the icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characteristics_extractor(icons, batch_size=10):\n",
    "    torch.cuda.empty_cache()\n",
    "    #modelo ResNet50 pré-treinado\n",
    "    model = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
    "    # Remover a última camada totalmente conectada (classificação)\n",
    "    model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "    # Modo de avaliação\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Criando o DataLoader\n",
    "\n",
    "    dataloader = DataLoader(icons, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    characteristics_extracted = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "            imgs = batch.to(device)  # Ensure the batch is on the GPU\n",
    "            if imgs.dim() == 3:  # Check if input is 3D and add batch dimension\n",
    "                imgs = imgs.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    features = model(imgs).squeeze()  # Remove batch and singleton dimensions if necessary\n",
    "                    characteristics_extracted.extend(features.cpu().numpy())  # Move back to CPU for numpy conversion\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"RuntimeError: {e}\")\n",
    "                    # Reduce batch size if running out of memory\n",
    "                    batch_size = max(1, batch_size // 2)\n",
    "                    dataloader = DataLoader(icons, batch_size=batch_size, shuffle=False)\n",
    "                    characteristics_extracted = []\n",
    "                    break\n",
    "\n",
    "    return np.array(characteristics_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducing_dimension(characteristics, variancia_desejada=0.99):\n",
    "\n",
    "    pca = PCA()\n",
    "    pca.fit(characteristics)\n",
    "    \n",
    "    # Calcular a variância acumulada\n",
    "    variancia_acumulada = np.cumsum(pca.explained_variance_ratio_)\n",
    "    \n",
    "    # Encontrar o número de componentes que explicam pelo menos a variância desejada\n",
    "    n_componentes = np.argmax(variancia_acumulada >= variancia_desejada) + 1\n",
    "    \n",
    "    # Ajustar PCA com o número de componentes determinado\n",
    "    pca = PCA(n_components=n_componentes)\n",
    "    reduced_characteristics = pca.fit_transform(characteristics)\n",
    "    \n",
    "    return reduced_characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate and decide the top most similar icons from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_alikes(characteristcs_given_icon, characteristics_bank, top_n=5):\n",
    "\n",
    "    distances = [euclidean(characteristcs_given_icon, c) for c in characteristics_bank]\n",
    "    alike_indexes = np.argsort(distances)\n",
    "    top_alike_indexes = alike_indexes[:top_n]\n",
    "\n",
    "    return top_alike_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to plot the most similar icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_similares(indices_similares, caminhos):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, idx in enumerate(indices_similares):\n",
    "        img = Image.open(caminhos[idx])\n",
    "        plt.subplot(1, len(indices_similares), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Imagem {idx}')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function to run the program, it groups all other functions and returns the path to the most similar icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoot(db_path, target_icon_path, height = 224, width = 224, variancia_desejada=0.99, top_n = 5):\n",
    "\n",
    "    icons_db, paths = load_icons_from_db(db_path = db_path, target_icon_path = target_icon_path)\n",
    "\n",
    "    preprocessed_icons = icon_pre_process(icons = icons_db, height = height, width = width)\n",
    "\n",
    "    characteristics = characteristics_extractor(preprocessed_icons)\n",
    "\n",
    "    reduced_characteristcs = reducing_dimension(characteristics = characteristics, variancia_desejada = variancia_desejada)\n",
    "    \n",
    "    characteristcs_given_icon = reduced_characteristcs[-1]\n",
    "\n",
    "    characteristics_bank = reduced_characteristcs[:-1]\n",
    "\n",
    "    alike_indexes = finding_alikes(characteristcs_given_icon = characteristcs_given_icon, characteristics_bank = characteristics_bank, top_n = top_n)\n",
    "\n",
    "    teste = paths[:-1]\n",
    "    alike_icons_paths = [teste[idx] for idx in alike_indexes]\n",
    "\n",
    "    \n",
    "    print(\"Path dos icones similares:\")\n",
    "    for path in alike_icons_paths:\n",
    "        print(\"\\n\" + path +\"\\n\")\n",
    "    \n",
    "    visualizar_similares(alike_indexes, paths[:-1])                                                                                                                      \n",
    "\n",
    "    return alike_icons_paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
